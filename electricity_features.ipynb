{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9d278481-f3c2-49f0-9e3e-509e960ed46b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pygeos\n",
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import matplotlib.colors as colors\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "75a8d767-8c96-41e5-94cd-2b872be1613f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/rigel/dsi/users/jm5352/miniconda3/envs/nenv/lib/python3.9/site-packages/openpyxl/worksheet/_reader.py:312: UserWarning: Data Validation extension is not supported and will be removed\n",
      "  warn(msg)\n",
      "/rigel/dsi/users/jm5352/miniconda3/envs/nenv/lib/python3.9/site-packages/openpyxl/worksheet/_reader.py:312: UserWarning: Data Validation extension is not supported and will be removed\n",
      "  warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2min 48s, sys: 5.33 s, total: 2min 53s\n",
      "Wall time: 2min 56s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "consumption= pd.read_pickle('./data/processed/merged_smoothed_monthly_by_meternumber_consumerid_march032021.pck').rename(\n",
    "    columns={'meter_serial_number':'Meter_Numb'}) # customer consumption data\n",
    "# meta data\n",
    "meta_df = pd.read_pickle('./data/processed/REG_metadata_3_Nov.pck') # customer_details\n",
    "# split column and add new columns to df, add meter_numb column\n",
    "a = meta_df['meter_serial_number_consumer_id'].str.split('_', expand=True)\n",
    "meta_df['Meter_Numb'] = a[0]\n",
    "meta_df['customer_ID'] = a[1]\n",
    "\n",
    "# convert column 'Meter_Numb' to float\n",
    "meta_df['Meter_Numb'] = pd.to_numeric(meta_df['Meter_Numb'],errors='coerce') \n",
    "meta_df['customer_ID'] = pd.to_numeric(meta_df['customer_ID'],errors='coerce')\n",
    "meta_df = meta_df[['meter_serial_number_consumer_id', 'vending_category_name',\n",
    "       'district_id', 'district', 'installation_date','eguide_categories', 'Meter_Numb']]\n",
    "\n",
    "# convert to datetime\n",
    "meta_df['installation_date'] = pd.to_datetime(meta_df.installation_date).dt.date\n",
    "\n",
    "# Reliability data\n",
    "mv_outages_2020 = pd.read_excel('./data/raw/reg_reliability/MV_Outages_2020.xlsx',\n",
    "                                sheet_name='Detailed',header=3)\n",
    "mv_outages_2019 = pd.read_excel('./data/raw/reg_reliability/MV_Outages_2016-2019.xlsx',\n",
    "                                sheet_name='2019',header=2)\n",
    "mv_outages_2018 = pd.read_excel('./data/raw/reg_reliability/MV_Outages_2016-2019.xlsx',\n",
    "                                sheet_name='2018',header=1)\n",
    "mv_outages_2017 = pd.read_excel('./data/raw/reg_reliability/MV_Outages_2016-2019.xlsx',\n",
    "                                sheet_name='2017',header=2)\n",
    "mv_outages_2016 = pd.read_excel('./data/raw/reg_reliability/MV_Outages_2016-2019.xlsx',\n",
    "                                sheet_name='2016',header=1)\n",
    "mv_outages_2016['Time(h)']=pd.to_timedelta(mv_outages_2016['Duration'].astype(str),\n",
    "                                           errors='coerce').dt.total_seconds()/3600\n",
    "\n",
    "\n",
    "# remove unnecessary columns \n",
    "mv_outages_2020 = mv_outages_2020.iloc[:,1:21] \n",
    "mv_outages_2019 = mv_outages_2019.iloc[:,1:15]\n",
    "mv_outages_2018 = mv_outages_2018.iloc[:,1:15]\n",
    "mv_outages_2017 = mv_outages_2017.iloc[:,1:]\n",
    "mv_outages_2016 = mv_outages_2016.iloc[:,1:]\n",
    "\n",
    "\n",
    "# to lower case\n",
    "reliablity_dfs = [mv_outages_2020, mv_outages_2019, mv_outages_2018, mv_outages_2017, mv_outages_2016]\n",
    "cols = ['Feeder','Substation Name','Hubs', 'Substation']\n",
    "for num,df in enumerate(reliablity_dfs):\n",
    "    for column in cols:\n",
    "        try:\n",
    "            df.loc[:,column] = df[column].str.lower()\n",
    "            df.loc[:,column] = df[column].str.strip()\n",
    "        except KeyError:\n",
    "            _ = (f'{column} absent in dataframe')\n",
    "##\n",
    "\n",
    "# meter GPS\n",
    "meter_gps = gpd.read_file('./data/raw/reg_gis/customer_locations_w_districts.geojson')\n",
    "\n",
    "# lines\n",
    "lines = gpd.read_file('./data/raw/reg_gis/LV_lines/lv_lines.shp')\n",
    "cols = ['Feeder_Nam','Substation','Branch_Nam']\n",
    "for column in cols:\n",
    "    lines.loc[:,column] = lines[column].str.lower()\n",
    "    lines.loc[:,column] = lines[column].str.strip()\n",
    "\n",
    "# Use projected CRS\n",
    "meter_gps = meter_gps.to_crs('epsg:32735')\n",
    "lines = lines.to_crs('epsg:32735')\n",
    "meter_cols = ['Meter_Numb','Transforme','MV_Feeder_',\n",
    "        'Branch_Nam', 'Connection', 'longitude',\n",
    "       'latitude', 'District', 'geometry']\n",
    "lines_cols = ['OBJECTID','Substation','Feeder_Nam','Branch_Nam','geometry']\n",
    "\n",
    "# merge meters with feeder lines\n",
    "meter_line_dist = 80\n",
    "meter_lines = meter_gps[meter_cols].sjoin_nearest(lines[lines_cols],\n",
    "                       how='left', distance_col='distance_to_line', max_distance=meter_line_dist)\n",
    "\n",
    "# meters with consumption\n",
    "meter_numbers = meta_df.Meter_Numb.unique().tolist()\n",
    "meter_lines_w_cons = meter_lines[meter_lines['Meter_Numb'].isin(meter_numbers)]\n",
    "\n",
    "# add installation dates\n",
    "meter_lines_w_cons = meter_lines_w_cons.merge(meta_df[['meter_serial_number_consumer_id','Meter_Numb','eguide_categories']],\n",
    "                        how='left',on='Meter_Numb').drop('index_right', axis=1)\n",
    "\n",
    "# Feeder reliability\n",
    "feeder_reliability_2020 = mv_outages_2020.groupby(['Hubs','Feeder'])['Time(h)'].agg(saifi_2020='count',\n",
    "                                                                  saidi_2020='sum').reset_index().rename(\n",
    "    columns={'Feeder':'Feeder_Nam','Hubs':'Hubs_2020'})\n",
    "\n",
    "feeder_reliability_2019 = mv_outages_2019.groupby(['Hubs','Feeder'])['Time(h)'].agg(saifi_2019='count',\n",
    "                                                                  saidi_2019='sum').reset_index().rename(\n",
    "    columns={'Feeder':'Feeder_Nam','Hubs':'Hubs_2019'})\n",
    "\n",
    "feeder_reliability_2018 = mv_outages_2018.groupby(['Hubs','Feeder'])['Time(h)'].agg(saifi_2018='count',\n",
    "                                                                  saidi_2018='sum').reset_index().rename(\n",
    "    columns={'Feeder':'Feeder_Nam','Hubs':'Hubs_2018'})\n",
    "\n",
    "feeder_reliability_2017 = mv_outages_2017.groupby(['Feeder'])['Time(h)'].agg(saifi_2017='count',\n",
    "                                                                  saidi_2017='sum').reset_index().rename(\n",
    "    columns={'Feeder':'Feeder_Nam'})\n",
    "\n",
    "feeder_reliability_2016 = mv_outages_2016.groupby(['Feeder'])['Time(h)'].agg(saifi_2016='count',\n",
    "                                                                  saidi_2016='sum').reset_index().rename(\n",
    "    columns={'Feeder':'Feeder_Nam'})\n",
    "\n",
    "# Merge dataframes\n",
    "meter_lines_w_cons_w_reliabilty = meter_lines_w_cons.merge(feeder_reliability_2020,how='left',on='Feeder_Nam')\n",
    "meter_lines_w_cons_w_reliabilty = meter_lines_w_cons_w_reliabilty.merge(feeder_reliability_2019,how='left',on='Feeder_Nam')\n",
    "meter_lines_w_cons_w_reliabilty = meter_lines_w_cons_w_reliabilty.merge(feeder_reliability_2018,how='left',on='Feeder_Nam')\n",
    "meter_lines_w_cons_w_reliabilty = meter_lines_w_cons_w_reliabilty.merge(feeder_reliability_2017,how='left',on='Feeder_Nam')\n",
    "meter_lines_w_cons_w_reliabilty = meter_lines_w_cons_w_reliabilty.merge(feeder_reliability_2016,how='left',on='Feeder_Nam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7ea62ab6-8616-4eef-955a-7f7df41a6c92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 36.6 s, sys: 8.75 s, total: 45.3 s\n",
      "Wall time: 45.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Merge meta data (customer descriptive info) with customer consumption data\n",
    "customer_consumption  = meta_df[['meter_serial_number_consumer_id','installation_date']].merge(consumption[\n",
    "    ['meter_serial_number_consumer_id','Meter_Numb','month','year','kWhs']], how='left', on='meter_serial_number_consumer_id')\n",
    "customer_consumption['installation_date'] = pd.to_datetime(customer_consumption.installation_date, format='%Y-%m-%d')\n",
    "\n",
    "# drop Rows without meter ids\n",
    "customer_consumption = customer_consumption[~customer_consumption.Meter_Numb.isna()]\n",
    "\n",
    "# Minimum number of consumption months in calendar year\n",
    "min_threshold = 6\n",
    "\n",
    "# Algorithm to compute annual consumption per meter\n",
    "install_start_year = 1996\n",
    "install_end_years   = [2012, 2013, 2014, 2015, 2016, 2017, 2018]\n",
    "consumption_years   = [2013, 2014, 2015, 2016, 2017, 2018, 2019]\n",
    "\n",
    "# Compute average mature meter/customer consumption\n",
    "all_annual_consumption = pd.DataFrame([])\n",
    "for i in range(len(consumption_years)):\n",
    "    # select install year range\n",
    "    install_years = customer_consumption[\n",
    "        (customer_consumption.installation_date>= pd.to_datetime(f'{install_start_year}-01-1') \n",
    "         )&(customer_consumption.installation_date<pd.to_datetime(f'{install_end_years[i]}-01-1'))]\n",
    "\n",
    "    # compute mature consumption, consumption a year after connection\n",
    "    mature_consumption = install_years[install_years.year==consumption_years[i]]\n",
    "    \n",
    "    # select meter ids that have atleast six months of consumption in a calendar year\n",
    "    Number_of_consumption_months = mature_consumption.groupby(['meter_serial_number_consumer_id'])['month'].count().reset_index().rename(columns={'month':'month_count'})\n",
    "    meter_serial_number_consumer_id_above_min_threshold = Number_of_consumption_months[Number_of_consumption_months.month_count>=min_threshold]\n",
    "    meter_serial_number_consumer_id_above_min_threshold_list = meter_serial_number_consumer_id_above_min_threshold.meter_serial_number_consumer_id.tolist()\n",
    "    \n",
    "    # filter out meter ids with less than six months consumption\n",
    "    mature_consumption = mature_consumption[mature_consumption.meter_serial_number_consumer_id.isin(meter_serial_number_consumer_id_above_min_threshold_list)]\n",
    "    \n",
    "    # compute customer annual consumption in target year\n",
    "    annual_mature_consumption = mature_consumption.groupby(\n",
    "        ['meter_serial_number_consumer_id'])['kWhs'].sum().reset_index().rename(columns={'kWhs':'annual_kWhs'}) # use meter_serial_number_consumer_id to compute annual consumption\n",
    "    annual_mature_consumption['consumption_year'] = consumption_years[i] # add correponding consumption year\n",
    "    all_annual_consumption = pd.concat([all_annual_consumption, annual_mature_consumption], ignore_index=True) # concat in a dataframe for all consumption years\n",
    "\n",
    "# add installation dates and customer types\n",
    "all_annual_consumption_with_install_dates = all_annual_consumption.merge(\n",
    "    meta_df[['meter_serial_number_consumer_id', 'Meter_Numb','installation_date','eguide_categories']], on='meter_serial_number_consumer_id', how='left')\n",
    "\n",
    "# create pivot table\n",
    "all_annual_consumption_with_install_dates_with_install_dates_pvt = all_annual_consumption_with_install_dates.pivot(index=['meter_serial_number_consumer_id','Meter_Numb','installation_date','eguide_categories'],\n",
    "                                                                                      columns='consumption_year', values='annual_kWhs').reset_index()\n",
    "# remove duplicates\n",
    "annual_consumption_no_dups = all_annual_consumption_with_install_dates_with_install_dates_pvt[~(all_annual_consumption_with_install_dates_with_install_dates_pvt[\n",
    "                                                                            ['Meter_Numb']].duplicated(keep='first'))]\n",
    "\n",
    "\n",
    "# merge reliablity with consumption\n",
    "reliability_w_consumption = meter_lines_w_cons_w_reliabilty.merge(annual_consumption_no_dups[['Meter_Numb',2019]],\n",
    "                                      how='left', on='Meter_Numb').rename(columns={2019:'annual_consumption_2019'})\n",
    "reliability_w_consumption_no_dups = reliability_w_consumption[~(reliability_w_consumption.Meter_Numb.duplicated(keep='first'))]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0624753-e3e3-4641-93fb-30d301f1db7b",
   "metadata": {},
   "source": [
    "## consumption in 2019"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "86e4fe89-6947-42d2-947f-807b6fb2cbc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_4201/2028390809.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  customer_consumption_annual.days_since_connection[customer_consumption_annual.days_since_connection<0] = 0\n"
     ]
    }
   ],
   "source": [
    "customer_consumption_annual = customer_consumption[customer_consumption.year==2019].copy()\n",
    "\n",
    "# add last add of month as end of monthly transaction period\n",
    "customer_consumption_annual['trans_period'] = pd.to_datetime(customer_consumption_annual[['year', 'month']].assign(day=lambda x: x['month'].apply(\n",
    "    lambda y: 31 if y in [1, 3, 5, 7, 8, 10, 12] else (30 if y in [4, 6, 9, 11] else (28 if y == 2 else np.nan)))))\n",
    "\n",
    "customer_consumption_annual['days_since_connection'] = ((customer_consumption_annual['trans_period'] - customer_consumption_annual['installation_date']).dt.days).astype(int)\n",
    "# replace negative days with zero\n",
    "customer_consumption_annual.days_since_connection[customer_consumption_annual.days_since_connection<0] = 0\n",
    "\n",
    "# groupby meter ID\n",
    "customer_consumption_annual_gpby = customer_consumption_annual.groupby('Meter_Numb')['days_since_connection'].max().reset_index()\n",
    "\n",
    "# merge\n",
    "reliabilty_cons_w_conn_days = reliability_w_consumption_no_dups.merge(customer_consumption_annual_gpby, how='left', on='Meter_Numb')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cddb37b-f9c9-49fb-ad7a-db686874b54d",
   "metadata": {},
   "source": [
    "### save dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "270c6281-8e19-4759-b740-36e71070d5c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "pck_fp = './data/processed/reliabilty_cons_w_conn_days_22_11_22_12am.pck'\n",
    "reliabilty_cons_w_conn_days.to_pickle(pck_fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4db2a8e2-20af-49e4-a7d3-42b408f35561",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4febac89-3e8a-4ec8-9682-db3002c8e4e5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ade2789b-7935-4ab4-b39e-ebff890e7a84",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72c88e91-fab0-475d-af8d-3d0f9fa78414",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8db22f64-31cc-43ca-9455-85064ade3374",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c6cb0d9-214e-477e-bebb-f0db6480bae2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
