{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c62168b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import sys\n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns\n",
    "import rasterio as rio\n",
    "from rasterio.plot import plotting_extent\n",
    "import earthpy.plot as ep\n",
    "import numpy as np\n",
    "from rasterstats import zonal_stats\n",
    "from shapely import wkt\n",
    "dir_path = './data/raw/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "96149096",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 11min 9s, sys: 20.6 s, total: 11min 29s\n",
      "Wall time: 11min 36s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Building footprints\n",
    "buildings = gpd.read_file('./data/raw/building_footprints_google_w_districts.geojson')\n",
    "# to lowercase\n",
    "buildings.District = buildings.District.str.lower()\n",
    "buildings['origin_origin_id'] = buildings.origin +'_'+buildings.origin_id # Identifier\n",
    "buildings_geom = buildings[['origin_origin_id','geometry']].copy()\n",
    "\n",
    "# Use projected CRS\n",
    "crs = 'epsg:32735'\n",
    "buildings_geom_utm_RW = buildings_geom.to_crs(crs)\n",
    "\n",
    "# meter data\n",
    "meter_data = pd.read_pickle('./data/processed/reliabilty_cons_w_conn_days_22_11_22_12am.pck')\n",
    "meter_building_dist = 80 # max distance between meter and building\n",
    "# Match building footprints to nearest meter locations\n",
    "meter_data_w_bf = gpd.sjoin_nearest(meter_data, buildings_geom_utm_RW,\n",
    "                                    how='left', distance_col=\"meter_building_distance\", max_distance = meter_building_dist).drop('index_right',axis=1)\n",
    "meter_data_w_bf_w_consumption = meter_data_w_bf[meter_data_w_bf.annual_consumption_2019.notna()] # remove buildings with no recorded consumption\n",
    "buildings_w_consumption_lst = meter_data_w_bf_w_consumption.origin_origin_id.unique().tolist()\n",
    "buildings_geom_w_consumption = buildings_geom_utm_RW[buildings_geom_utm_RW.origin_origin_id.isin(buildings_w_consumption_lst)].copy() # buildings with consumption\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1678fd44-2e92-4576-a8fb-cfe1534ce157",
   "metadata": {},
   "source": [
    "# ADD Raster features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7740db08-fbe8-45da-b75c-868d2cd58219",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5.27 s, sys: 3 s, total: 8.27 s\n",
      "Wall time: 9.47 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# load building features\n",
    "building_features = pd.read_pickle('./data/processed/buildings_features_22_11_22_4pm.pck') # load building features from vectors\n",
    "\n",
    "# convert to village features\n",
    "village_features = building_features.groupby('village_id').mean()\n",
    "\n",
    "## Import raster features\n",
    "# import landcover files\n",
    "df_lc_2015 = pd.read_pickle(dir_path+'lc_2015.pck')\n",
    "df_lc_2010 = pd.read_pickle(dir_path+'lc_2010.pck')\n",
    "df_lc_2000 = pd.read_pickle(dir_path+'lc_2000.pck')\n",
    "df_lc_1990 = pd.read_pickle(dir_path+'lc_1990.pck')\n",
    "# import population files\n",
    "df_popn_2005 = pd.read_pickle(dir_path+'village_mean_popn_2005.pck')\n",
    "df_popn_2015 = pd.read_pickle(dir_path+'village_mean_popn_2015.pck')\n",
    "# import elevation file\n",
    "df_elev = pd.read_pickle(dir_path+'village_mean_elevation.pck')\n",
    "# import AWI\n",
    "df_AWI_2016 = pd.read_pickle(dir_path+'AWI_2016.pck')\n",
    "df_AWI_2017 = pd.read_pickle(dir_path+'AWI_2017.pck')\n",
    "df_AWI_2018 = pd.read_pickle(dir_path+'AWI_2018.pck')\n",
    "df_AWI_2019 = pd.read_pickle(dir_path+'AWI_2019.pck')\n",
    "# import spending\n",
    "df_spending_2016 = pd.read_pickle(dir_path+'spending_2016.pck')\n",
    "df_spending_2017 = pd.read_pickle(dir_path+'spending_2017.pck')\n",
    "df_spending_2018 = pd.read_pickle(dir_path+'spending_2018.pck')\n",
    "df_spending_2019 = pd.read_pickle(dir_path+'spending_2019.pck')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6e384b97-1549-49d2-a5c0-4d65506dc457",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 548 ms, sys: 56.6 ms, total: 604 ms\n",
      "Wall time: 605 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# merge vector and raster features\n",
    "\n",
    "# LULC\n",
    "village_features = village_features.merge(df_lc_2015[['village_id','majority']], how='left',on='village_id').rename(columns={'majority':'majority_2015'})\n",
    "village_features = village_features.merge(df_lc_2010[['village_id','majority']], how='left',on='village_id').rename(columns={'majority':'majority_2010'})\n",
    "village_features = village_features.merge(df_lc_2000[['village_id','majority']], how='left',on='village_id').rename(columns={'majority':'majority_2000'})\n",
    "village_features = village_features.merge(df_lc_1990[['village_id','majority']], how='left',on='village_id').rename(columns={'majority':'majority_1990'})\n",
    "# Popn\n",
    "village_features = village_features.merge(df_popn_2005[['village_id','mean_popn']], how='left',on='village_id').rename(columns={'mean_popn':'mean_popn_2005'})\n",
    "village_features = village_features.merge(df_popn_2015[['village_id','mean_popn']], how='left',on='village_id').rename(columns={'mean_popn':'mean_popn_2015'})\n",
    "village_features = village_features.merge(df_elev[['village_id','mean_elevation']], how='left',on='village_id')\n",
    "# AWI\n",
    "village_features = village_features.merge(df_AWI_2016[['village_id','mean_AWI']], how='left',on='village_id').rename(columns={'mean_AWI':'mean_AWI_2016'})\n",
    "village_features = village_features.merge(df_AWI_2017[['village_id','mean_AWI']], how='left',on='village_id').rename(columns={'mean_AWI':'mean_AWI_2017'})\n",
    "village_features = village_features.merge(df_AWI_2018[['village_id','mean_AWI']], how='left',on='village_id').rename(columns={'mean_AWI':'mean_AWI_2018'})\n",
    "village_features = village_features.merge(df_AWI_2019[['village_id','mean_AWI']], how='left',on='village_id').rename(columns={'mean_AWI':'mean_AWI_2019'})\n",
    "# spending\n",
    "village_features = village_features.merge(df_spending_2016[['village_id','mean_spending']], how='left',on='village_id').rename(columns={'mean_spending':'mean_spending_2016'})\n",
    "village_features = village_features.merge(df_spending_2017[['village_id','mean_spending']], how='left',on='village_id').rename(columns={'mean_spending':'mean_spending_2017'})\n",
    "village_features = village_features.merge(df_spending_2018[['village_id','mean_spending']], how='left',on='village_id').rename(columns={'mean_spending':'mean_spending_2018'})\n",
    "village_features = village_features.merge(df_spending_2019[['village_id','mean_spending']], how='left',on='village_id').rename(columns={'mean_spending':'mean_spending_2019'})\n",
    "\n",
    "# village density\n",
    "    # all buildings\n",
    "village_density = building_features.groupby(['village_id'])['origin_origin_id'].count().reset_index().rename(columns={'origin_origin_id':'village_density_all'})\n",
    "village_features = village_features.merge(village_density, how='left',on='village_id')\n",
    "   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d6618205-2890-4b0a-886b-fd1be915008c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 31.5 s, sys: 940 ms, total: 32.5 s\n",
      "Wall time: 32.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "\n",
    "def filter_categories(list_items):\n",
    "    '''\n",
    "    function to select unique categories for each building\n",
    "    If building has one non-residential categorize it as non residential\n",
    "    '''\n",
    "    item = ''\n",
    "    if len(list_items)>1:\n",
    "        \n",
    "        for item in list_items:\n",
    "            if item=='Non Residential':\n",
    "                item = 'Non Residential'\n",
    "            else:\n",
    "                item= 'Residential'\n",
    "        return item\n",
    "    else:\n",
    "        return list_items[0] \n",
    "\n",
    "#unique categories for each building\n",
    "meter_data_cats = meter_data_w_bf_w_consumption.groupby(['origin_origin_id'])['eguide_categories'].unique().reset_index()\n",
    "meter_data_cats['eguide_categories'] = meter_data_cats['eguide_categories'].apply(lambda x: filter_categories(x))\n",
    "\n",
    "    \n",
    "# Building 2019 total consumption\n",
    "buiding_kWh = meter_data_w_bf_w_consumption.groupby(['origin_origin_id'])['annual_consumption_2019'].sum(min_count=1).reset_index()\n",
    "# Building days since connection, saifi, saidi\n",
    "meter_data_features =meter_data_w_bf_w_consumption.groupby(['origin_origin_id'])[['days_since_connection','saifi_2020','saifi_2019','saifi_2018','saifi_2017','saifi_2016',\n",
    "                                                                                 'saidi_2020','saidi_2019','saidi_2018','saidi_2017','saidi_2016']].max().reset_index()\n",
    "\n",
    "# # merge meter features\n",
    "# meter_data_features = meter_data_features.merge(buiding_kWh, how='left',on='origin_origin_id')\n",
    "# meter_data_features = meter_data_features.merge(meter_data_cats, how='left',on='origin_origin_id')\n",
    "\n",
    "# merge meter and village id\n",
    "meter_data_features = meter_data_features.merge(building_features[['village_id','origin_origin_id']], on='origin_origin_id', how='left')\n",
    "buiding_kWh = buiding_kWh.merge(building_features[['village_id','origin_origin_id']], on='origin_origin_id', how='left')\n",
    "meter_data_cats = meter_data_cats.merge(building_features[['village_id','origin_origin_id']], on='origin_origin_id', how='left')\n",
    "meter_data_cats['eguide_categories']=meter_data_cats['eguide_categories'].apply(lambda x: 'Non Residential' if x=='other' else x) # meter categories\n",
    "\n",
    "# Groupby villages\n",
    "meter_data_cats = meter_data_cats.groupby(['village_id','eguide_categories'])[['eguide_categories','origin_origin_id']].count(\n",
    ").rename(columns={'eguide_categories':'categories'}).reset_index().drop('origin_origin_id', axis=1).pivot(\n",
    "    index='village_id',columns='eguide_categories',values='categories').reset_index().fillna(0)\n",
    "buiding_kWh = buiding_kWh.groupby('village_id').mean().reset_index()\n",
    "meter_data_features = meter_data_features.groupby('village_id').mean().reset_index()\n",
    "\n",
    "# merge village meter features\n",
    "meter_features = meter_data_features.merge(meter_data_cats, how='inner',on='village_id')\n",
    "village_meter_features = village_features.merge(meter_features, how='inner',on='village_id')\n",
    "village_meter_features = village_meter_features.merge(buiding_kWh, how='inner',on='village_id')\n",
    "# meter_stats = meter_data_features.groupby('village_id').mean().reset_index()\n",
    "# village_meter_features = village_cats.merge(meter_stats, how='inner', on='village_id')\n",
    "\n",
    "# # merge village features with meter features\n",
    "# village_features = village_features.merge(village_meter_features, how='left', on='village_id')\n",
    "\n",
    "# # village level dataset\n",
    "data_villages = village_meter_features[village_meter_features.annual_consumption_2019.notna()]\n",
    "data_villages['Residential_percent'] =data_villages['Residential']/(data_villages['Non Residential']+data_villages['Residential'])\n",
    "data_villages['non_Residential_percent'] =data_villages['Non Residential']/(data_villages['Non Residential']+data_villages['Residential'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6b4049e3-9e6f-47c4-b04d-83c218e2727d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# residential and non residential percentages\n",
    "data_villages['Residential_percent'] =data_villages['Residential']/(data_villages['Non Residential']+data_villages['Residential'])\n",
    "data_villages['non_Residential_percent'] =data_villages['Non Residential']/(data_villages['Non Residential']+data_villages['Residential'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "38b5c785-e772-4f14-ac31-a0500a1a4a35",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "village_id                             0\n",
       "area_in_meters                         0\n",
       "n_bldgs_1km_away                       0\n",
       "school_building_dist                   0\n",
       "health_building_dist                   0\n",
       "trade_building_dist                    0\n",
       "coffee_building_dist                   0\n",
       "tourism_building_dist                  0\n",
       "industrypark_building_dist             0\n",
       "District_offices_building_dist         0\n",
       "religious_centres_building_dist        0\n",
       "sports_centres_building_dist           0\n",
       "major_towns_building_dist              0\n",
       "bus_stations_building_dist             0\n",
       "landmark_building_dist                 0\n",
       "road_netwk_building_dist               0\n",
       "national_paved_road_building_dist      0\n",
       "national_unpaved_road_building_dist    0\n",
       "area_km                                0\n",
       "majority_2015                          0\n",
       "majority_2010                          0\n",
       "majority_2000                          0\n",
       "majority_1990                          0\n",
       "mean_popn_2005                         0\n",
       "mean_popn_2015                         0\n",
       "mean_elevation                         0\n",
       "mean_AWI_2016                          0\n",
       "mean_AWI_2017                          0\n",
       "mean_AWI_2018                          0\n",
       "mean_AWI_2019                          0\n",
       "mean_spending_2016                     0\n",
       "mean_spending_2017                     0\n",
       "mean_spending_2018                     0\n",
       "mean_spending_2019                     0\n",
       "village_density_all                    0\n",
       "days_since_connection                  0\n",
       "saifi_2020                             0\n",
       "saifi_2019                             0\n",
       "saifi_2018                             0\n",
       "saifi_2017                             0\n",
       "saifi_2016                             0\n",
       "saidi_2020                             0\n",
       "saidi_2019                             0\n",
       "saidi_2018                             0\n",
       "saidi_2017                             0\n",
       "saidi_2016                             0\n",
       "Non Residential                        0\n",
       "Residential                            0\n",
       "annual_consumption_2019                0\n",
       "Residential_percent                    0\n",
       "non_Residential_percent                0\n",
       "district                               0\n",
       "province                               0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "village_boundaries = gpd.read_file('./data/raw/Villages_boundaries.geojson').rename(columns={'code_vill_':'village_id'})\n",
    "village_boundaries['district'] = village_boundaries['district'].str.lower()\n",
    "\n",
    "# merge\n",
    "data_villages = data_villages.merge(village_boundaries[['village_id','district','province']], how='left',on='village_id')\n",
    "\n",
    "# remove NaNs\n",
    "columns_w_nans_dist = ['mean_AWI_2019','mean_AWI_2018','mean_AWI_2017','mean_AWI_2016','mean_spending_2019','mean_spending_2018','mean_spending_2017','mean_spending_2016',\n",
    "                  'saifi_2020','saifi_2019','saifi_2018','saifi_2017','saifi_2016','saidi_2020','saidi_2019','saidi_2018','saidi_2017','saidi_2016',\n",
    "                 ]\n",
    "for col in columns_w_nans_dist:\n",
    "    data_villages[col] = data_villages.groupby(\"district\")[col].transform(lambda x: x.fillna(x.mean())) # use distict average\n",
    "    \n",
    "columns_w_nans_prov = [\n",
    "                  'saifi_2020','saifi_2019','saifi_2018','saifi_2017','saifi_2016','saidi_2020','saidi_2019','saidi_2018','saidi_2017','saidi_2016',\n",
    "                 ]\n",
    "for col in columns_w_nans_prov:\n",
    "    data_villages[col] = data_villages.groupby(\"province\")[col].transform(lambda x: x.fillna(x.mean())) # use province average\n",
    "data_villages = data_villages.drop(['village_id','district','province'],axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40c38b1a-4b10-4eb3-8bb9-3e6c3b186e7e",
   "metadata": {},
   "source": [
    "### Save Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "fe482973-90e6-42e0-8ebb-fd490e88dfbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "pck_fp = './data/processed/data_Villages_1_12_22_3pm_cat_percent_mean.pck'\n",
    "data_villages.to_pickle(pck_fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d7dfa4a-0f8e-42e2-a085-18a9960f5d53",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
